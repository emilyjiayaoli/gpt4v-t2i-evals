{'id': 15, 'scores': array([[0. , 0. ],
       [0.5, 0. ]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/15/0.png', 'img2_path': './winoground/images/15/1.png', 'caption1': 'there are more skiers than snowboarders', 'caption2': 'there are more snowboarders than skiers', 'i1c1_result': {'score': 0.0, 'description': 'There are more skiers than snowboarders', 'reasoning': 'In the image provided, there are three individuals on skis and one individual on a snowboard, which clearly shows that there are more skiers than snowboarders.'}, 'i1c2_result': {'score': 0.0, 'description': 'There are more snowboarders than skiers', 'reasoning': 'In the provided image, there are three individuals on skis and only one individual on a snowboard. Thus, the number of skiers is greater than the number of snowboarders, making the caption very unlikely to be a correct description of the image.'}, 'i2c1_result': {'score': 0.5, 'description': 'Neutral', 'reasoning': "The image shows one skier and one snowboarder, making it impossible to determine if there are more skiers than snowboarders based on this image alone. Since the sample size is too small and not indicative of the overall population of skiers and snowboarders, no conclusion can be drawn about the caption's accuracy."}, 'i2c2_result': {'score': 0.0, 'description': 'In the image, there is one skier and one snowboarder.', 'reasoning': 'The image shows one person skiing and one person snowboarding, hence the number of skiers and snowboarders is equal, not more snowboarders than skiers as the caption suggests.'}}
{'id': 24, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/24/0.png', 'img2_path': './winoground/images/24/1.png', 'caption1': 'the person closer to the camera weightlifts and the person farther from the camera runs', 'caption2': 'the person closer to the camera runs and the person farther from the camera weightlifts', 'i1c1_result': {'score': 1.0, 'description': 'The caption match is very likely', 'reasoning': 'The person closer to the camera is holding what appears to be a pair of dumbbells above their head, which is indicative of weightlifting. The person farther from the camera is using a treadmill, which is a piece of equipment commonly used for running.'}, 'i1c2_result': {'score': 1.0, 'description': 'The person closer to the camera is lifting weights overhead, and the person farther from the camera appears to be running on a treadmill.', 'reasoning': 'The image clearly shows a person in the foreground lifting dumbbells above their head, which is a weightlifting exercise. In the background, another person is on a treadmill with a running posture, which indicates they are indeed running.'}, 'i2c1_result': {'score': 1.0, 'description': 'The image-captions match assessment', 'reasoning': 'The person closer to the camera is on a treadmill, which is commonly used for running, while the person farther from the camera is holding dumbbells, which is indicative of weightlifting. Both observations match the respective activities mentioned in the caption.'}, 'i2c2_result': {'score': 1.0, 'description': "The caption's accuracy is very high with the content of the image", 'reasoning': 'The person closer to the camera is clearly running on a treadmill, while the person farther from the camera appears to be holding dumbbells, suggesting that they are weightlifting, thus closely matching the provided caption.'}}
{'id': 43, 'scores': array([[0., 0.],
       [0., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/43/0.png', 'img2_path': './winoground/images/43/1.png', 'caption1': 'a big cat is next to a small dog', 'caption2': 'a small cat is next to a big dog', 'i1c1_result': {'score': 0.0, 'description': 'Mismatch of animals in the image compared to the caption', 'reasoning': "The image features a cat and a dog, which correspond to the 'big cat' and 'small dog' terms in the caption; however, the term 'big cat' typically refers to larger wild feline species such as lions, tigers, leopards, etc., not a domestic cat which is shown in the image. Consequently, the caption does not accurately describe the animals present in the image."}, 'i1c2_result': {'score': 0.0, 'description': 'A small cat is next to a big dog', 'reasoning': 'The image shows a small dog next to a cat. The size of the cat is not particularly small, and the dog present in the image is not big but is in fact a small breed of dog. Therefore, the caption does not accurately describe the subjects in the image.'}, 'i2c1_result': {'score': 0.0, 'description': 'The image shows a large dog and a small cat, not a big cat and a small dog.', 'reasoning': "The image does not match the caption because the animal next to the small dog is a large dog, not a big cat. 'Big cat' typically refers to a large wild feline such as lions, tigers, or leopards, not domestic cats or dogs."}, 'i2c2_result': {'score': 1.0, 'description': 'A small cat is next to a big dog', 'reasoning': "The image shows a small cat sitting in close proximity to a large dog. The size discrepancy between the two animals is evident, with the dog appearing significantly bigger than the cat, fitting the description of a 'big dog'. The cat is small in comparison, matching the description of a 'small cat'. They are indeed next to each other, making the caption very accurate for this image."}}
{'id': 55, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/55/0.png', 'img2_path': './winoground/images/55/1.png', 'caption1': 'the green one can fit inside the blue one and the blue one can fit outside the green one', 'caption2': 'the green one can fit outside the blue one and the blue one can fit inside the green one', 'i1c1_result': {'score': 1.0, 'description': 'The green one can fit inside the blue one and the blue one can fit outside the green one', 'reasoning': 'The image shows a set of nesting dolls, also known as matryoshka dolls. These dolls are designed in such a way that each smaller doll can fit inside the next larger one. In this case, the green doll is smaller and can fit inside the blue one, and the blue one is larger and can encompass the green one, along with the others shown in the image.'}, 'i1c2_result': {'score': 1.0, 'description': 'The image shows a set of Russian nesting dolls, also known as matryoshka dolls. These dolls are designed to fit one inside the other, with each subsequent doll being smaller than the last.', 'reasoning': 'The dolls depicted have a design that inherently allows them to fit one inside another based on their decreasing sizes. The green doll appears smaller than the blue one, suggesting that it can fit outside the blue one, while the blue one can fit inside the green one because it is larger.'}, 'i2c1_result': {'score': 1.0, 'description': 'The green one can fit inside the blue one and the blue one can fit outside the green one', 'reasoning': 'The objects in the image are matryoshka dolls, which are designed in such a way that each doll can be nested inside another doll that is larger. Typically, each doll is painted in different colors. The statement implies that among the two dolls referenced, the green one is smaller and can fit within the blue one, and vice versa, which aligns with the design and function of matryoshka dolls.'}, 'i2c2_result': {'score': 1.0, 'description': 'The green one can fit outside the blue one and the blue one can fit inside the green one', 'reasoning': 'The image shows a set of Matryoshka dolls, also known as Russian nesting dolls, which are designed to fit one inside the other based on their size. Typically, each doll can fit inside a larger one and can contain a smaller one within it. As the green and blue dolls are different in size, the description is very likely to be accurate.'}}
{'id': 57, 'scores': array([[1., 0.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/57/0.png', 'img2_path': './winoground/images/57/1.png', 'caption1': 'someone bakes the dough before the dough is eaten', 'caption2': 'the dough is eaten before someone bakes the dough', 'i1c1_result': {'score': 1.0, 'description': 'The image shows a person placing a baking tray with uncooked cookie dough into an oven.', 'reasoning': 'The image depicts the action of baking, which typically involves placing dough into an oven before it is consumed. The cookies are clearly unbaked, suggesting that the next step is to bake them in the oven.'}, 'i1c2_result': {'score': 0.0, 'description': 'The image shows a person putting a tray of raw, unbaked cookies into an oven, which suggests that they are about to bake the dough.', 'reasoning': 'The dough appears intact and ready for baking rather than partially or completely consumed. There are no visible indications that the dough has been eaten, so the image does not match the caption stating that the dough is eaten before someone bakes it.'}, 'i2c1_result': {'score': 1.0, 'description': 'someone bakes the dough before the dough is eaten', 'reasoning': "The image shows a person, apparently in the process of baking, with raw dough visible in a bowl and on a baking sheet. The person is wearing a chef's hat and is playfully taking a taste of the raw dough, suggesting that they will likely bake the dough before it is fully consumed."}, 'i2c2_result': {'score': 1.0, 'description': 'The image shows a person who appears to be eating raw dough directly from the mixing bowl with a joyful expression.', 'reasoning': "The individual in the image is depicted with their mouth open, biting into some raw dough held on a spatula, which fits the caption 'the dough is eaten before someone bakes the dough'. The presence of unbaked dough balls on a tray in the foreground suggests that some of the dough is intended for baking, which aligns with the second part of the caption."}}
{'id': 63, 'scores': array([[1., 0.],
       [0., 0.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/63/0.png', 'img2_path': './winoground/images/63/1.png', 'caption1': 'no people wear blue shirts and six people wear white shirts', 'caption2': 'six people wear blue shirts and no people wear white shirts', 'i1c1_result': {'score': 1.0, 'description': 'The image matches the provided caption.', 'reasoning': 'The image shows six individuals, all wearing white shirts. There are no individuals wearing blue shirts visible in the image. Therefore, the description in the caption accurately reflects the clothing colors of the people in the image.'}, 'i1c2_result': {'score': 0.0, 'description': 'The caption does not match the image', 'reasoning': "The provided image shows six people wearing white shirts, not blue shirts. Therefore, it is very unlikely that the caption 'six people wear blue shirts and no people wear white shirts' matches the image."}, 'i2c1_result': {'score': 0.0, 'description': 'The image shows multiple people wearing blue shirts', 'reasoning': "The caption states 'no people wear blue shirts' which is directly contradicted by the image content, as all individuals are wearing blue shirts. Additionally, the caption mentions 'six people wear white shirts,' but there are no individuals wearing white shirts visible in the image. Therefore, the caption does not accurately describe the image."}, 'i2c2_result': {'score': 0.0, 'description': 'Mismatch between image content and caption', 'reasoning': 'The image shows six individuals, but they are not all wearing blue shirts. One individual is wearing a light gray or similar colored shirt, not white. Furthermore, no one in the image is wearing a white shirt, which partially agrees with the caption. However, since not all individuals are wearing blue shirts, the caption does not accurately describe the image.'}}
{'id': 65, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/65/0.png', 'img2_path': './winoground/images/65/1.png', 'caption1': "the animal's eyes are bigger than the person's", 'caption2': "the person's eyes are bigger than the animal's", 'i1c1_result': {'score': 1.0, 'description': "The animal's eyes are bigger than the person's", 'reasoning': "The image shows a close-up side-by-side comparison of a person's face and a horse's eye. The horse's eye is clearly larger than the person's eye, supporting the caption that the animal's eyes are bigger than the person's."}, 'i1c2_result': {'score': 0.0, 'description': "The person's eyes are smaller than the animal's", 'reasoning': "In the provided image, the close-up of the person and the animal (which is a horse) shows that the horse's eye is significantly larger than the person's eye. It is clear that the animal's eye size exceeds that of the human's, making the caption 'the person's eyes are bigger than the animal's' very unlikely to be accurate."}, 'i2c1_result': {'score': 0.0, 'description': "The animal's eyes are smaller than the person's", 'reasoning': "Based on the visual assessment of the image, the animal, which appears to be a small rodent like a hamster, has significantly smaller eyes compared to the human's, therefore the caption 'the animal's eyes are bigger than the person's' does not match the image."}, 'i2c2_result': {'score': 1.0, 'description': "The person's eyes are bigger than the animal's", 'reasoning': "In the image provided, the person (a young girl) is holding a small animal (appears to be a hamster) close to her face. The size of the girl's eyes is visibly larger than that of the eyes of the animal she is holding. Therefore, the caption that 'the person's eyes are bigger than the animal's' is very likely to be accurate."}}
{'id': 69, 'scores': array([[1., 1.],
       [0., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/69/0.png', 'img2_path': './winoground/images/69/1.png', 'caption1': 'almost everyone is in a boat and one is swimming', 'caption2': 'one is in a boat and almost everyone is swimming', 'i1c1_result': {'score': 1.0, 'description': 'The image closely matches the caption', 'reasoning': "The image depicts a large number of people on a boat and one person swimming in the water, which corresponds well with the caption 'almost everyone is in a boat and one is swimming'."}, 'i1c2_result': {'score': 1.0, 'description': "The provided image shows a large boat with several people on board, and there are multiple individuals swimming in the water or sitting on the shore. This matches the caption 'one is in a boat and almost everyone is swimming'.", 'reasoning': "While the boat is significant in size and cannot be classified as 'one in a boat' in a literal sense, it is reasonable to assume that the caption refers to the general situation where there is one boat present and several people swimming. The rest of the statement 'almost everyone is swimming' is metaphorical, indicating that apart from the people in the boat, others are enjoying the water, which is consistent with the image."}, 'i2c1_result': {'score': 0.0, 'description': 'The image shows a group of people swimming in water and one person in a kayak.', 'reasoning': "The caption 'almost everyone is in a boat and one is swimming' does not accurately describe the image since the vast majority of the individuals captured in the image are swimming, with only one person visible in a kayak. Therefore, the statement is inconsistent with the scene depicted in the photograph."}, 'i2c2_result': {'score': 1.0, 'description': 'One is in a boat and almost everyone is swimming', 'reasoning': 'The image shows a group of individuals in the water, the majority of whom are swimming, and there is one individual in a kayak or small boat, thus closely matching the caption.'}}
{'id': 73, 'scores': array([[0.75, 0.  ],
       [0.  , 1.  ]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/73/0.png', 'img2_path': './winoground/images/73/1.png', 'caption1': 'watching the present', 'caption2': 'presenting the watch', 'i1c1_result': {'score': 0.75, 'description': 'Watching the present', 'reasoning': "The image shows a family interacting with a present, possibly during a holiday celebration. The term 'watching the present' could be interpreted as observing or engaging with a current event or gift, which is happening in the image. However, if the caption implies a temporal connotation, such as being aware of the current time period, it is less directly represented in the image."}, 'i1c2_result': {'score': 0.0, 'description': 'The image does not depict a watch being presented', 'reasoning': 'The image shows a family gathering, possibly during a holiday, with an adult woman and a child engaging with a gift wrapped in paper. There is no visible watch or any indication that a watch is being presented.'}, 'i2c1_result': {'score': 0.0, 'description': 'Watching the Present', 'reasoning': "The image shows a person sitting at a table with a smartwatch on their wrist, appearing to initiate contactless payment with a card reader. The action depicted is specifically related to making a payment, not 'watching' as in observing or looking at something. The caption 'watching the present' does not accurately describe what is happening in the image."}, 'i2c2_result': {'score': 1.0, 'description': 'Presenting the watch', 'reasoning': 'The image shows a person holding out their arm with a watch clearly visible on their wrist, as if they are showing it off or presenting it. Additionally, there is a focus on the watch, suggesting it is a point of interest or importance in the photo.'}}
{'id': 74, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/74/0.png', 'img2_path': './winoground/images/74/1.png', 'caption1': 'walking out on a rock', 'caption2': 'rocking out on a walk', 'i1c1_result': {'score': 1.0, 'description': 'The image matches the caption', 'reasoning': "The image shows a person walking on a rocky outcrop or formation with a clear view of a body of water and mountains in the background, which fits the description of 'walking out on a rock'."}, 'i1c2_result': {'score': 0.0, 'description': 'rocking out on a walk', 'reasoning': "The person in the image appears to be walking carefully over rocky terrain, surrounded by a mountainous landscape and a lake. There is no indication that they are listening to music or engaging in behavior typically associated with 'rocking out,' such as playing an air guitar or displaying energetic, music-driven movement. The caption 'rocking out on a walk' suggests an individual actively enjoying music in an expressive manner while walking, which is not depicted in the image."}, 'i2c1_result': {'score': 0.0, 'description': 'The person is not walking out on a rock', 'reasoning': 'The person in the image is walking along a paved surface with a structured background that appears to be a wall. There are no rocks or natural terrain visible in the image.'}, 'i2c2_result': {'score': 1.0, 'description': 'rocking out on a walk', 'reasoning': "The person in the image appears to be walking while listening to music and making a 'rock on' hand gesture, which is a common gesture associated with enjoying music and often linked to the rock genre specifically. Her joyful facial expression and movement suggests she is enjoying the music, supporting the 'rocking out' aspect of the caption."}}
{'id': 83, 'scores': array([[0.  , 1.  ],
       [0.  , 0.75]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/83/0.png', 'img2_path': './winoground/images/83/1.png', 'caption1': 'a diagram showing movement from right to left', 'caption2': 'a diagram showing movement from left to right', 'i1c1_result': {'score': 0.0, 'description': 'a diagram showing movement from right to left', 'reasoning': 'The image shows a strategic diagram presumably for a football (soccer) play with arrows indicating movement of the players and the ball. The majority of the arrows point from left to right, which contradicts the caption stating that it shows movement from right to left.'}, 'i1c2_result': {'score': 1.0, 'description': 'This image depicts a hand drawing a strategy or a play on a sports chalkboard, with arrows indicating movement, most of which point from left to right across the board.', 'reasoning': "The arrows drawn on the chalkboard mostly indicate movement from the left side of the chalkboard to the right, which is in alignment with the provided caption 'a diagram showing movement from left to right'."}, 'i2c1_result': {'score': 0.0, 'description': 'The image shows a soccer strategy on a chalkboard.', 'reasoning': "The diagram is a strategy board for soccer with arrows pointing in various directions, not consistently from right to left, indicating players' movement on the field rather than a unidirectional leftward movement."}, 'i2c2_result': {'score': 0.75, 'description': 'A diagram showing movement', 'reasoning': "The image contains a chalkboard with a diagram that appears to be a strategy or play pattern, commonly used in sports such as football (soccer) or American football. The diagram includes arrows that indicate movement. While some arrows do indicate movement from left to right, there are also arrows pointing in various other directions. Therefore, the match to the caption 'a diagram showing movement from left to right' is 'Somewhat Likely' because it's not exclusively in that direction."}}
{'id': 87, 'scores': array([[1., 1.],
       [0., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/87/0.png', 'img2_path': './winoground/images/87/1.png', 'caption1': 'The uncaged bird has an opened cage door', 'caption2': 'The caged bird has an unopened cage door', 'i1c1_result': {'score': 1.0, 'description': "The image shows a bird in flight, just outside of an open birdcage, which matches the caption 'The uncaged bird has an opened cage door'.", 'reasoning': "The bird is depicted outside and at a short distance from the cage, with the door of the birdcage open. No other explanation is given for the image, and there's no evidence suggesting that it does not match the caption provided."}, 'i1c2_result': {'score': 1.0, 'description': 'The caged bird has an unopened cage door', 'reasoning': "The image shows a bird flying out of a cage where the door appears to be ajar or open, which matches the caption 'The caged bird has an unopened cage door.' Although 'unopened' typically means not opened, in this context it may refer to the door now being in a state that does not confine the bird, suggesting the bird has the opportunity to exit the cage, which aligns with the visual information present."}, 'i2c1_result': {'score': 0.0, 'description': 'The uncaged bird has an opened cage door', 'reasoning': 'The image shows a bird inside a cage, and the door of the cage appears to be closed, not open. Hence, the caption does not accurately describe the current state of the bird and the cage.'}, 'i2c2_result': {'score': 1.0, 'description': 'The caged bird has an unopened cage door', 'reasoning': "The image shows a bird inside a cage with a door that appears to be unopened. The door's fastening mechanism does not seem to be disturbed, suggesting that the door has not been opened recently or is currently in a closed position."}}
{'id': 91, 'scores': array([[1., 0.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/91/0.png', 'img2_path': './winoground/images/91/1.png', 'caption1': 'clothing on lines', 'caption2': 'lines on clothing', 'i1c1_result': {'score': 1.0, 'description': 'The provided image shows clothing items such as shirts and pants hanging on a clothesline outdoors, with a person actively hanging a sheet. A laundry basket and pins are also visible, which are commonly associated with the activity of drying clothes.', 'reasoning': "The image directly corresponds to the caption 'clothing on lines' as it visually depicts clothing being dried on lines, which is the primary focus of the image."}, 'i1c2_result': {'score': 0.0, 'description': 'The image shows clothes being hung on a line outside, with a person adjusting a large white cloth.', 'reasoning': "The image depicts clothing hung out to dry on a washing line. The caption 'lines on clothing' suggests that the clothing should have lines as a pattern or feature, but this image does not clearly show any lines as a pattern on the clothing items themselves."}, 'i2c1_result': {'score': 1.0, 'description': 'Clothing on lines', 'reasoning': "The image shows an article of clothing, which looks like a striped shirt, spread out and appears to be placed against a flat surface rather than hanging on a line. However, since the caption does not specify that the clothing must be hanging and because clothes lines are commonly used for drying shirts like the one in the image, it is still very likely that this image could be associated with the caption 'clothing on lines'."}, 'i2c2_result': {'score': 1.0, 'description': 'The image shows a piece of clothing with lines', 'reasoning': "The image clearly depicts a striped garment with an arrangement of horizontal lines, which directly corresponds to the concept of 'lines on clothing'."}}
{'id': 95, 'scores': array([[0.25, 0.  ],
       [0.  , 0.  ]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/95/0.png', 'img2_path': './winoground/images/95/1.png', 'caption1': 'handing a hammer', 'caption2': 'hammering a hand', 'i1c1_result': {'score': 0.25, 'description': 'The person is holding a hammer out towards the camera', 'reasoning': "The person in the image appears to be holding a hammer out towards the viewer rather than handing it to someone else. The action of handing over typically involves another individual who would be receiving the hammer, but no other person is visible in the image, making the precise action of 'handing a hammer' somewhat unlikely."}, 'i1c2_result': {'score': 0.0, 'description': "The image does not match the caption 'hammering a hand'.", 'reasoning': 'The person in the image is holding a hammer and appears to be preparing to use it on an object, not on a hand. There is no indication that the hammer is being used on a hand, which makes the correspondence between the image and the caption very unlikely.'}, 'i2c1_result': {'score': 0.0, 'description': 'handing a hammer', 'reasoning': "The image shows a close-up of a hammer being used to drive a nail into a surface, held by a person's hand. There is no exchange, handover, or gesture that would indicate the action of 'handing' a hammer to another person."}, 'i2c2_result': {'score': 0.0, 'description': 'Hammering a nail, not a hand', 'reasoning': "The image shows a hand holding a hammer and driving a nail into a surface but no hand is being hammered. The caption 'hammering a hand' does not accurately describe the action in the image."}}
{'id': 102, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/102/0.png', 'img2_path': './winoground/images/102/1.png', 'caption1': 'real cat with toy baby', 'caption2': 'toy cat with real baby', 'i1c1_result': {'score': 1.0, 'description': 'Real cat with toy baby', 'reasoning': "The image depicts a living cat that appears to be interacting with a small, inanimate object resembling a toy baby doll. The cat's fur, eyes, and other physical features indicate that it is a real animal, rather than an illustration or a fake. The toy baby has characteristics such as being disproportionately small compared to the cat, having an overly simplistic facial representation, and wearing a patterned fabric outfit, which suggests it is not a real baby but a toy."}, 'i1c2_result': {'score': 0.0, 'description': 'Toy cat with real baby', 'reasoning': "The image depicts a real cat interacting with a toy that resembles a human baby. The toy's proportions and details such as the size of the head, the texture and appearance of the hair, and the stiffness of the limbs are indicative of an inanimate object rather than a real baby. Therefore, the caption 'toy cat with real baby' is not accurate."}, 'i2c1_result': {'score': 0.0, 'description': 'Real cat with toy baby', 'reasoning': 'The image shows an infant lying down with a toy, which appears to be a stuffed animal, not a real cat. There is no real cat visible in the image.'}, 'i2c2_result': {'score': 1.0, 'description': 'The image depicts a plush toy resembling a cartoonish character in close proximity to a sleeping baby. The toy is obviously inanimate with exaggerated features not found in real cats, while the baby appears to be a real human infant.', 'reasoning': "Upon visual inspection, the item next to the baby has characteristics of a toy, such as bright colors, yarn-like texture, and a stylized design not resembling a living animal. Additionally, the baby has natural human features and proportions, making it clearly a real baby. Thus, the caption 'toy cat with real baby' very likely matches the image."}}
{'id': 103, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/103/0.png', 'img2_path': './winoground/images/103/1.png', 'caption1': 'the lion is loud and the lionness is quiet', 'caption2': 'the lion is quiet and the lionness is loud', 'i1c1_result': {'score': 1.0, 'description': 'The image depicts a male lion (lion) roaring or with its mouth wide open, while a lioness appears to be calm and relaxed.', 'reasoning': 'The lion is displaying a behavior that could be associated with being loud, such as roaring, while the lionness is sitting quietly. This visual evidence supports the caption provided.'}, 'i1c2_result': {'score': 0.0, 'description': 'The lion is quiet and the lionness is loud', 'reasoning': "In the image provided, the lion is depicted with its mouth open in a roaring or yawning posture, which contradicts the description of the lion being 'quiet'. The lioness in the background appears to be calm and is not showing any signs of being 'loud'. Therefore, the image does not match the caption provided."}, 'i2c1_result': {'score': 0.0, 'description': 'The lion is loud and the lionness is quiet', 'reasoning': "In the image provided, the lioness is shown with an open mouth as if she is roaring or making a loud noise, while the lion appears to be quiet. This contradicts the caption's implication that the lion is the loud one and the lioness is quiet."}, 'i2c2_result': {'score': 1.0, 'description': 'The image shows a lioness with her mouth open, appearing to make noise, and a lion that is quiet.', 'reasoning': "The lioness is depicted with her mouth open as if she is roaring or making noise, while the lion is not showing any sign of being loud, which aligns well with the caption stating 'the lion is quiet and the lionness is loud'."}}
{'id': 105, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/105/0.png', 'img2_path': './winoground/images/105/1.png', 'caption1': 'light colored dog with dark colored cat', 'caption2': 'dark colored dog with light colored cat', 'i1c1_result': {'score': 1.0, 'description': 'light colored dog with dark colored cat', 'reasoning': 'The image shows a dog with light-colored fur and a cat with dark fur, matching the description provided.'}, 'i1c2_result': {'score': 0.0, 'description': 'dark colored dog with light colored cat', 'reasoning': 'The image shows a light-colored dog and a dark-colored cat, which is the exact opposite of the provided caption.'}, 'i2c1_result': {'score': 0.0, 'description': 'The image depicts a dark colored dog with a light colored cat', 'reasoning': 'The image shows a dog with a dark coat and a cat with a light-colored coat, which is the opposite of the caption provided.'}, 'i2c2_result': {'score': 1.0, 'description': 'The image matches the caption', 'reasoning': 'The image depicts a dark colored dog alongside a light colored cat. The dog appears to be black and brown, while the cat has a predominantly light cream or ginger color. These descriptions align closely with the caption provided.'}}
{'id': 110, 'scores': array([[0., 0.],
       [0., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/110/0.png', 'img2_path': './winoground/images/110/1.png', 'caption1': "there's one blue and many yellow balls", 'caption2': "there's one yellow and many blue balls", 'i1c1_result': {'score': 0.0, 'description': 'The image does not match the caption', 'reasoning': 'The image shows multiple orange balls and one grey ball, not blue as described in the caption.'}, 'i1c2_result': {'score': 0.0, 'description': "There's one yellow and many blue balls", 'reasoning': "The image shows multiple orange balls and one grey ball. There are no blue balls present, making the caption's description inaccurate."}, 'i2c1_result': {'score': 0.0, 'description': 'Mismatch between the colors described in the caption and the colors visible in the image', 'reasoning': "The caption describes one blue ball and many yellow balls. However, the image displays one yellow ball and many blue balls, which is the opposite of the caption's description. Therefore, the likelihood that the caption accurately describes the image is very unlikely."}, 'i2c2_result': {'score': 1.0, 'description': "The image matches the caption 'there's one yellow and many blue balls'.", 'reasoning': 'The image clearly shows a single yellow ball and multiple blue balls on a surface that is half blue and half white. There are no other colored balls in the image.'}}
{'id': 119, 'scores': array([[0., 0.],
       [0., 0.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/119/0.png', 'img2_path': './winoground/images/119/1.png', 'caption1': 'the dress on the left is long and the dress on the right is short', 'caption2': 'the dress on the left is short and the dress on the right is long', 'i1c1_result': {'score': 0.0, 'description': "The provided image does not depict two dresses side-by-side for comparison; therefore, it does not visually validate the statement about 'the dress on the left' or 'the dress on the right'.", 'reasoning': 'In the image, there is only one dress visible, which is worn by a person. There is no second dress to compare its length against. The visible dress appears to be long, but without a second dress, the comparison cannot be made. Hence, the likelihood that the caption matches the image is very unlikely.'}, 'i1c2_result': {'score': 0.0, 'description': 'The dress on the left is long and the dress on the right is short', 'reasoning': 'In the provided image, the person on the left side is wearing a long dress with a skirt that extends to the floor, while the person on the right side is wearing a short dress with a hemline above the knee.'}, 'i2c1_result': {'score': 0.0, 'description': 'The dresses seen in the image do not match the description provided', 'reasoning': 'In the image, the woman on the left is wearing a short dress, while the reflection in the mirror on the right shows a long dress. Thus, the caption describing the dress on the left as long and the dress on the right as short does not accurately reflect what is shown in the image.'}, 'i2c2_result': {'score': 0.0, 'description': 'The dress on the left is short and the dress on the right is long', 'reasoning': "In the provided image, there appears to be only one dress, which is being worn by the person standing in front of the mirror. This dress is long, reaching to the floor. There is no visible dress on the left that can be used for comparison, rendering the assessment of the caption as 'Very Unlikely' because it references two dresses with specific length attributes that do not match the content of the image."}}
{'id': 128, 'scores': array([[0., 0.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/128/0.png', 'img2_path': './winoground/images/128/1.png', 'caption1': 'the fruit is heavy while the junk food is light', 'caption2': 'the fruit is light while the junk food is heavy', 'i1c1_result': {'score': 0.0, 'description': 'Contrary to the caption provided', 'reasoning': 'In the image, a traditional balance scale shows junk food (cupcakes) on one side and a piece of fruit (an apple) on the other. The scale is tipped in favor of the fruit, which indicates that the fruit is heavier compared to the junk food, not lighter as the caption suggests.'}, 'i1c2_result': {'score': 0.0, 'description': 'The image depicts a balance scale with cupcakes on one side and an apple on the other.', 'reasoning': "The visual weight of the items on the scale contradicts the caption. The side with the apple is hanging lower than the side with the cupcakes, suggesting the fruit is heavier than the junk food in this representation, contrary to the statement 'the fruit is light while the junk food is heavy'."}, 'i2c1_result': {'score': 1.0, 'description': 'The fruit is heavy while the junk food is light', 'reasoning': 'In the image, there is a clear visual representation of a balance scale where a piece of fruit, which appears to be an apple, is weighing down one side, while a cupcake is on the lighter side. This corresponds to the literal interpretation of the caption, suggesting the fruit (apple) is heavier than the junk food (cupcake).'}, 'i2c2_result': {'score': 1.0, 'description': 'The image shows a balanced scale with a green apple on one side and a cupcake on the other. The apple is on the lower side of the scale, indicating it is heavier, while the cupcake is on the raised side, suggesting it is lighter.', 'reasoning': "The image contradicts the caption 'the fruit is light while the junk food is heavy' because it visually represents the opposite. The apple, representing the fruit, appears heavier than the cupcake, which represents the junk food, based on their positions on the scale."}}
{'id': 132, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/132/0.png', 'img2_path': './winoground/images/132/1.png', 'caption1': 'there is a clock wall', 'caption2': 'there is a wall clock', 'i1c1_result': {'score': 1.0, 'description': "The image matches the caption 'there is a clock wall'", 'reasoning': 'The image shows multiple clocks of various styles and sizes hung on a wall with a person holding another clock, signifying that the wall is indeed covered with clocks, which aligns well with the caption.'}, 'i1c2_result': {'score': 1.0, 'description': 'There is a wall clock', 'reasoning': "The image shows multiple clocks on the wall, confirming that the caption 'there is a wall clock' accurately describes the content of the image."}, 'i2c1_result': {'score': 1.0, 'description': 'There is a clock on the wall', 'reasoning': "The image clearly shows a single clock hanging on a wall above a chalkboard. The caption 'there is a clock wall' is likely trying to describe the presence of a clock on the wall; however, the wording of the caption could also imply a wall full of clocks which is not depicted in the image. Assuming the intent is to mention the presence of a clock on the wall, the caption is very likely accurate."}, 'i2c2_result': {'score': 1.0, 'description': 'There is a wall clock in the image', 'reasoning': 'The image clearly depicts a wall clock mounted above a chalkboard in a classroom setting.'}}
{'id': 142, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/142/0.png', 'img2_path': './winoground/images/142/1.png', 'caption1': 'there is more wood than metal', 'caption2': 'there is more metal than wood', 'i1c1_result': {'score': 1.0, 'description': 'There is more wood than metal', 'reasoning': 'The image shows a wooden barrel, which is primarily made of wood with metal bands holding the wooden slats together. The visible surface area and volume of wood clearly surpass the metal components of the barrel.'}, 'i1c2_result': {'score': 0.0, 'description': 'The barrel in the image is primarily constructed of wooden staves bound together by metal rings.', 'reasoning': 'The visual evidence suggests that the barrel is made mostly of wood, with the metal being used only as bands to hold the wooden parts together. There is clearly more visible wood surface area than metal.'}, 'i2c1_result': {'score': 0.0, 'description': 'There is more wood than metal', 'reasoning': "The image shows a metal tea kettle with a wooden handle. The amount of metal used in the kettle itself is considerably more than the wood used for the handle. Therefore, the caption 'there is more wood than metal' does not accurately describe the proportions of materials visible in the image."}, 'i2c2_result': {'score': 1.0, 'description': 'The image shows a kettle that appears to be made mostly of metal, with only the handle seemingly made of wood.', 'reasoning': 'The body, spout, and lid of the kettle are all made of metal. The wooden part is limited to the handle, which is a small portion of the entire kettle. Therefore, there is significantly more metal present than wood.'}}
{'id': 150, 'scores': array([[1., 0.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/150/0.png', 'img2_path': './winoground/images/150/1.png', 'caption1': 'check a rip', 'caption2': 'rip a check', 'i1c1_result': {'score': 1.0, 'description': 'The image shows a person holding a pair of denim jeans with a noticeable tear on them.', 'reasoning': "The phrase 'check a rip' can be interpreted as an action to look for or inspect a tear in a material. The image clearly displays a person inspecting a ripped area of a pair of jeans, which aligns with the typical use of the phrase in the given context."}, 'i1c2_result': {'score': 0.0, 'description': "The phrase 'rip a check' does not visually or contextually match the image.", 'reasoning': "The provided image shows a pair of denim jeans with a torn or ripped section. The caption 'rip a check' is not clearly related to the image, as the image does not depict a financial check being torn or any other action that could reasonably be associated with the phrase 'rip a check'. The caption more likely refers to the act of tearing a paper check, which is not represented in the image."}, 'i2c1_result': {'score': 1.0, 'description': 'Check a rip', 'reasoning': "The image shows a piece of paper with a clearly visible tear or rip, which corresponds to the action of checking a rip in a material object, making it 'Very Likely' that the image matches the caption."}, 'i2c2_result': {'score': 1.0, 'description': 'Image matches the caption', 'reasoning': 'The image shows a torn paper with visible elements typically associated with a check, such as a date and a signature. The tearing of the paper seems consistent with the act of ripping a check.'}}
{'id': 158, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/158/0.png', 'img2_path': './winoground/images/158/1.png', 'caption1': "there's a human in a stroller next to a dog", 'caption2': "there's a dog in a stroller next to a human", 'i1c1_result': {'score': 1.0, 'description': 'The image matches the caption provided', 'reasoning': "The image clearly shows a dog next to a stroller in which a young human child is seated. Both elements described in the caption, 'a human in a stroller' and 'next to a dog,' are present and accurately depicted in the image."}, 'i1c2_result': {'score': 0.0, 'description': 'The photo contains a dog next to a stroller; however, the stroller does not contain another dog, but a human baby instead.', 'reasoning': 'Based on the content of the image, it shows a dog standing next to a stroller in which a human baby is seated, not a dog. Thus, the caption does not accurately describe what is depicted in the image.'}, 'i2c1_result': {'score': 0.0, 'description': "There's a human in a stroller next to a dog", 'reasoning': "The image shows a dog sitting in a stroller, not a human. Additionally, there is a person sitting beside the stroller on a bench, but the person is not in the stroller. There is also a dog in the background but it's not right next to the stroller, therefore the caption does not accurately describe the image."}, 'i2c2_result': {'score': 1.0, 'description': "there's a dog in a stroller next to a human", 'reasoning': 'The image depicts a dog sitting in a stroller and there is a human sitting on a bench next to the stroller. This matches the caption provided.'}}
{'id': 165, 'scores': array([[1.  , 0.25],
       [1.  , 1.  ]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/165/0.png', 'img2_path': './winoground/images/165/1.png', 'caption1': "there's a phone on a map", 'caption2': "there's a map on a phone", 'i1c1_result': {'score': 1.0, 'description': "There's a phone on a map", 'reasoning': 'The provided image clearly depicts a smartphone placed on top of an open paper map. Additionally, there are other travel-related items visible, such as a camera and sunglasses, which are common in a traveling or navigation context, supporting the setting described by the caption.'}, 'i1c2_result': {'score': 0.25, 'description': "The phone's screen is visible and turned off or displaying a black screen", 'reasoning': 'In the provided image, a physical map is clearly visible with a hand pointing to a location on it. Additionally, there is a camera, sunglasses, and what appear to be travel brochures or guides on the table. A smartphone is also visible, but the screen is turned off or displaying a black screen. There is no visible map displayed on the phone screen.'}, 'i2c1_result': {'score': 1.0, 'description': "There's a phone on a map", 'reasoning': "The image shows a person holding a smartphone with what appears to be a navigational map application open on the screen, indicating their current location and a route plotted. This closely matches the caption 'there's a phone on a map.'"}, 'i2c2_result': {'score': 1.0, 'description': 'The image shows a phone with a visible interface that appears to be a map application. There are street outlines and a location marker, which are typical features of map applications on phones.', 'reasoning': "The visual evidence of a map interface on the phone's screen matches the description of 'there's a map on a phone'. The presence of street outlines, a location marker, and navigation controls leave little ambiguity about the function of the application being displayed."}}
{'id': 172, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/172/0.png', 'img2_path': './winoground/images/172/1.png', 'caption1': 'the water is filled with plastic', 'caption2': 'the plastic is filled with water', 'i1c1_result': {'score': 1.0, 'description': 'The water is filled with plastic', 'reasoning': 'The image clearly shows a large amount of plastic debris floating in the water. There are several identifiable pieces of plastic waste, including what appear to be bags and fragments of other plastic items. This suggests a significant presence of plastic pollution within the body of water depicted.'}, 'i1c2_result': {'score': 0.0, 'description': 'The plastic is filled with water', 'reasoning': "The image displays a variety of plastic debris floating in water, suggesting pollution in a body of water such as an ocean or sea. While the plastics are surrounded by water, the phrase 'filled with water' typically implies that water is contained within the items themselves. Since most of the visible plastic debris are not designed to hold water and appear to be floating rather than submerged and filled, the caption does not accurately describe the scene."}, 'i2c1_result': {'score': 0.0, 'description': 'The image shows a clean plastic water bottle.', 'reasoning': 'The caption suggests the presence of plastic pollution within a body of water. The image, however, displays a single plastic bottle that appears to be sealed and does not depict any body of water filled with plastic.'}, 'i2c2_result': {'score': 1.0, 'description': 'The plastic is filled with water', 'reasoning': 'The image shows a plastic bottle that appears to be filled with a clear liquid, most likely water, given its transparency and the context of such bottles typically being used to contain water.'}}
{'id': 180, 'scores': array([[1., 0.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/180/0.png', 'img2_path': './winoground/images/180/1.png', 'caption1': 'the baby on the phone is next to an adult', 'caption2': 'the baby is next to an adult on the phone', 'i1c1_result': {'score': 1.0, 'description': 'The baby on the phone is next to an adult', 'reasoning': 'The image shows a baby holding a smartphone-like device, sitting very close to an adult who seems to be sleeping. The proximity of the baby to the adult aligns with the caption provided.'}, 'i1c2_result': {'score': 0.0, 'description': 'The caption does not match the image', 'reasoning': 'The adult in the image is lying down with eyes closed and does not appear to be on the phone. The baby is holding a tablet or electronic device and not a phone.'}, 'i2c1_result': {'score': 1.0, 'description': 'The baby on the phone is next to an adult', 'reasoning': 'The image shows an adult holding a baby while talking on the phone. Since the baby is in close proximity to the adult and appears to be under their care, the caption accurately describes the scenario depicted in the image.'}, 'i2c2_result': {'score': 1.0, 'description': 'The baby is next to an adult on the phone', 'reasoning': "The image shows an adult holding a baby while engaging in a phone conversation. The baby is positioned next to the adult, fulfilling the caption's description."}}
{'id': 183, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/183/0.png', 'img2_path': './winoground/images/183/1.png', 'caption1': 'the orange on the left is moldy while the orange on the right is fresh', 'caption2': 'the orange on the right is moldy while the orange on the left is fresh', 'i1c1_result': {'score': 1.0, 'description': 'The orange on the left is moldy while the orange on the right is fresh', 'reasoning': 'The image shows two oranges, with the one on the left covered in white mold spots, indicating it is moldy. The orange on the right appears to have a fresh, healthy orange skin with no visible mold or discoloration.'}, 'i1c2_result': {'score': 1.0, 'description': 'The orange on the right is moldy while the orange on the left is fresh', 'reasoning': 'The image shows two oranges on a wooden surface. The orange on the right side of the image appears to be fresh with a vibrant orange color and taut skin, indicating it has not begun to deteriorate. The orange on the left, however, is covered in a white and greenish-blue mold, a clear sign that it has gone bad. The contrast between the two oranges in terms of their surface appearance supports the claim provided in the caption.'}, 'i2c1_result': {'score': 1.0, 'description': "The orange on the left appears to have a normal, healthy skin typical of a fresh orange. The orange in the middle has some mold on it, which can be misinterpreted as the 'orange on the right' described in the caption. However, the orange on the far right is completely covered in green and blue mold and is clearly not fresh.", 'reasoning': 'The visual assessment shows one orange with a fresh appearance and another that is overwhelmingly moldy, indicating spoilage. Despite a slight discrepancy in the caption regarding the position of the oranges, the broader context of the caption aligns with the visible condition of the oranges.'}, 'i2c2_result': {'score': 1.0, 'description': 'The orange on the right is moldy while the orange on the left is fresh.', 'reasoning': 'In the image, the orange on the left appears to have a healthy, bright orange color typical of a fresh orange. The orange on the right is covered with green and white fuzzy growth, which is consistent with mold. The middle orange shows signs of mold as well, but the caption specifically compares the oranges on the right and the left.'}}
{'id': 213, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/213/0.png', 'img2_path': './winoground/images/213/1.png', 'caption1': 'more water than oil', 'caption2': 'more oil than water', 'i1c1_result': {'score': 1.0, 'description': 'more water than oil', 'reasoning': 'The image shows a glass with a clear liquid, presumably water, filling the majority of the container. Additionally, there is a yellowish liquid, seemingly oil, being poured into the glass or rising to the top, present in a smaller quantity compared to the water. Oil and water are immiscible, and oil tends to float on water due to being less dense, which is consistent with the observation in the image. Therefore, based on the visible proportions, it appears there is indeed more water than oil in the glass.'}, 'i1c2_result': {'score': 0.0, 'description': 'Assessment of Image-Caption Match', 'reasoning': "The image shows a stream of oil being poured into a glass of water. The oil droplets are visible as they float on the surface of the water due to oil's lower density and immiscibility with water. The volume of water in the glass significantly exceeds the volume of oil being added or already present, which suggests that there is more water than oil in the glass."}, 'i2c1_result': {'score': 0.0, 'description': 'More water than oil', 'reasoning': "The image shows a clear separation between two fluids in a jar, with the bottom layer being blue (likely water with added color) and the top layer being yellow (likely representing oil). Since oil floats on water due to lower density, and the yellow layer is on top, it suggests that there is less oil than water present in the jar. Thus, the caption 'more water than oil' appears to accurately describe the situation in the image."}, 'i2c2_result': {'score': 1.0, 'description': "'More oil than water' matches the provided image.", 'reasoning': "The image shows a glass container with two distinct layers of liquid. The top layer, which is a lighter color, appears to be oil due to its separation from the bottom layer and its characteristic color and texture. The bottom layer is likely water, indicated by its color and the fact that it is denser than the oil, causing it to settle at the bottom. The volume of the top layer is visually greater than that of the bottom layer, making it 'very likely' that the image matches the caption 'more oil than water'."}}
{'id': 214, 'scores': array([[1.  , 0.75],
       [1.  , 1.  ]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/214/0.png', 'img2_path': './winoground/images/214/1.png', 'caption1': 'a person cries while another person wearing jewelry above their shoulders consoles', 'caption2': 'a person consoles while another person wearing jewelry above their shoulders cries', 'i1c1_result': {'score': 1.0, 'description': 'a person cries while another person wearing jewelry above their shoulders consoles', 'reasoning': "The image shows one person with a hand covering their face, which could indicate crying. The other person has their hand on the possibly crying person's shoulder in a comforting gesture. Although there is no clear evidence of visible tears, the overall body language suggests consolation. The person consoling is wearing a sleeveless top, potentially exposing the area where jewelry above their shoulders could be worn, although no specific jewelry is visible in the image."}, 'i1c2_result': {'score': 0.75, 'description': 'a person consoles while another person wearing jewelry above their shoulders cries', 'reasoning': 'The image shows one person comforting another who appears to be in distress, which matches the first part of the caption about consoling. The individual who is being consoled is covering their face, a common sign of crying or distress. However, no visible jewelry above the shoulders, such as earrings or necklaces, can be confirmed from this angle, so the second part of the caption is not clearly supported by the image.'}, 'i2c1_result': {'score': 1.0, 'description': 'The image shows one person with tears on their face suggestive of crying, and another person close by, whose hand is positioned as if they could be offering comfort. The person close by appears to be wearing a garment with a textured collar, which could be perceived as jewelry above their shoulders.', 'reasoning': 'The visual cues in the image strongly suggest that the person is crying given the visible tears and facial expression. The proximity and orientation of the second person, along with the position of their hand, indicate a comforting gesture. The textured garment could be mistaken for jewelry above their shoulders in a quick assessment.'}, 'i2c2_result': {'score': 1.0, 'description': 'a person consoles while another person wearing jewelry above their shoulders cries', 'reasoning': 'The image shows one person with a concerned expression gently touching the face of another person who appears to be crying, as indicated by the visible tear and sorrowful facial expression. The person who is crying is wearing earrings, which is a form of jewelry above their shoulders.'}}
{'id': 259, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/259/0.png', 'img2_path': './winoground/images/259/1.png', 'caption1': 'Young person playing baseball with a green bat and blue ball', 'caption2': 'Young person playing baseball with a blue bat and green ball', 'i1c1_result': {'score': 1.0, 'description': 'Young person playing baseball with a green bat and blue ball', 'reasoning': 'The image shows a young individual holding a green bat and looking up at a blue ball in mid-air, which matches the activity of playing baseball as described in the caption.'}, 'i1c2_result': {'score': 1.0, 'description': 'The image matches the caption', 'reasoning': 'The image shows a young person who appears to be playing a game with a bat and ball. The bat is blue, and the ball is green, which directly corresponds to the caption provided. The individual appears to be in a batting pose, which is consistent with playing baseball.'}, 'i2c1_result': {'score': 1.0, 'description': 'Image matches the caption', 'reasoning': 'The image shows a young person swinging a blue bat at a blue ball. Although the specific shades may vary, the given descriptors match the objects and person in the image.'}, 'i2c2_result': {'score': 1.0, 'description': 'Young person playing with a blue bat and green ball', 'reasoning': 'The image shows a child who appears to be playing with a blue bat and a green ball against an orange background. This matches the description provided in the caption.'}}
{'id': 265, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/265/0.png', 'img2_path': './winoground/images/265/1.png', 'caption1': 'there are more pineapples than boxes', 'caption2': 'there are more boxes than pineapples', 'i1c1_result': {'score': 1.0, 'description': 'The image shows multiple pineapples with only partial views of boxes. The visible pineapples outnumber the partial views of boxes.', 'reasoning': 'Based on the visible information in the image, multiple pineapples are seen stacked in what appears to be a market setting, while only parts of wooden boxes are visible amongst the pineapples. No full box is completely visible, and since the pineapples are clearly more numerous than the portions of boxes seen, it is very likely there are more pineapples than boxes.'}, 'i1c2_result': {'score': 0.0, 'description': 'The image shows several pineapples packed closely together, and they are clearly more numerous than the wooden crates visible in the image.', 'reasoning': 'From the image, it is observable that each wooden crate contains multiple pineapples. Only parts of two or three crates are visible, whereas there are many pineapples. Therefore, it is very unlikely that there are more boxes than pineapples.'}, 'i2c1_result': {'score': 0.0, 'description': 'There are more pineapples than boxes', 'reasoning': 'In the image provided, there is a variety of fruits and vegetables displayed in various boxes. Upon counting, there are more visible boxes than pineapples. Each box contains different produce including pineapples, but pineapples are not in the majority compared to the total number of boxes visible.'}, 'i2c2_result': {'score': 1.0, 'description': 'There are more boxes than pineapples', 'reasoning': "In the provided image, it is visible that there are many boxes containing various fruits and vegetables, with only a few pineapples visible among them. The number of boxes present in the image far exceeds the number of pineapples, making it very likely that the statement 'there are more boxes than pineapples' is accurate."}}
{'id': 268, 'scores': array([[0., 0.],
       [0., 0.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/268/0.png', 'img2_path': './winoground/images/268/1.png', 'caption1': 'the cat on the left of the photo has its right paw ahead of its left', 'caption2': 'the cat on the left of the photo has its left paw ahead of its right', 'i1c1_result': {'score': 0.0, 'description': 'The cat on the left of the photo has its paws positioned side by side', 'reasoning': 'The animals in the image are snow leopards, not domestic cats. As such, the description does not apply. Furthermore, both snow leopards have their front paws placed side by side rather than one ahead of the other.'}, 'i1c2_result': {'score': 0.0, 'description': 'The image does not contain any cats', 'reasoning': "The image shows two snow leopards. The caption is not applicable because it refers to a cat's paws, which cannot be assessed for snow leopards in this context."}, 'i2c1_result': {'score': 0.0, 'description': 'The cat on the left of the photo has its right paw ahead of its left', 'reasoning': "The provided image shows two kittens side by side. For the kitten on the left, both paws are positioned evenly, none ahead of the other. Therefore, the caption does not accurately describe the position of the left cat's paws."}, 'i2c2_result': {'score': 0.0, 'description': 'The cat on the left of the photo does not have its left paw ahead of its right', 'reasoning': 'The cat on the left of the photo appears to have both its paws at the same level, with neither paw being ahead of the other. The position of its left and right paws are symmetrical and neither is extended forward.'}}
{'id': 276, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/276/0.png', 'img2_path': './winoground/images/276/1.png', 'caption1': 'the younger person is making noise while the other is silent', 'caption2': 'the younger person is silent while the other is making noise', 'i1c1_result': {'score': 1.0, 'description': 'The younger person is making noise while the other is silent', 'reasoning': 'In the image, we see a younger individual with their mouth wide open in what appears to be a shout or scream, indicating the likelihood that they are making noise. Meanwhile, another person appears to be resting or sleeping on a bed, and their closed mouth and peaceful posture suggest silence, making the caption very likely a match.'}, 'i1c2_result': {'score': 1.0, 'description': 'the younger person is silent while the other is making noise', 'reasoning': 'In the image, there is a younger person with their mouth wide open as if they are yelling or screaming, which indicates they are making noise. The other person appears to be asleep and therefore silent, which aligns with the caption.'}, 'i2c1_result': {'score': 1.0, 'description': 'The younger person is silent while the older person is using a megaphone', 'reasoning': 'In the image, the younger individual is looking at a smartphone with a neutral facial expression, and there is no indication that they are making noise. Conversely, the older individual is actively using a megaphone directed at the younger person, which is typically associated with making noise.'}, 'i2c2_result': {'score': 1.0, 'description': 'The older person is using a megaphone which is commonly used to make noise or amplify sound, indicating that they are likely making noise. The younger person is silently looking at their phone and appears not to be making any noise.', 'reasoning': "The visual evidence suggests that the older individual is actively using a megaphone, a device designed to amplify sound, and hence is 'making noise.' The younger person is focused on their phone and does not exhibit any behavior indicative of making noise. Therefore, based on visual cues alone, the caption ‘the younger person is silent while the other is making noise’ is aligned with the activities depicted in the image."}}
{'id': 277, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/277/0.png', 'img2_path': './winoground/images/277/1.png', 'caption1': 'the one on the left is happy and the other is sad', 'caption2': 'the one on the left is sad and the other is happy', 'i1c1_result': {'score': 1.0, 'description': 'The one on the left is happy and the other is sad', 'reasoning': 'The individual on the left is displaying a broad smile, indicative of happiness. In contrast, the individual on the right has a frown and a somber facial expression, which are typical indicators of sadness. Therefore, the caption accurately describes their apparent emotional states.'}, 'i1c2_result': {'score': 1.0, 'description': 'The one on the left is sad and the other is happy', 'reasoning': 'In the provided image, the person on the left is displaying facial features and body language commonly associated with sadness, such as a downturned mouth and a somber expression, whereas the person on the right is smiling broadly and has an open, engaged body posture that indicates happiness.'}, 'i2c1_result': {'score': 1.0, 'description': 'The one on the left is happy and the other is sad', 'reasoning': 'The left side of the image shows half of a face with a smile, indicative of happiness. The right side shows half of a face with a frown and a downturned mouth corner, which are common indicators of sadness. The visual expressions strongly match the given caption.'}, 'i2c2_result': {'score': 1.0, 'description': 'The one on the left is sad and the other is happy', 'reasoning': 'The facial expression of the person on the left side of the photograph shows characteristics that are commonly associated with sadness, such as a downward turn of the mouth, a slightly furrowed brow, and a less open eye expression. Conversely, the facial expression of the person on the right side of the photograph has traits commonly associated with happiness, such as a slightly upturned mouth and a relaxed, open eye expression.'}}
{'id': 297, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/297/0.png', 'img2_path': './winoground/images/297/1.png', 'caption1': 'the pet on the right is white and the one on the left is not', 'caption2': 'the pet on the left is white and the one on the right is not', 'i1c1_result': {'score': 1.0, 'description': 'The pet on the right is white and the one on the left is not', 'reasoning': 'In the image provided, there are two dogs. The dog on the right side of the image as viewed appears to be white, and the dog on the left side is black. The caption accurately describes the colors of the pets as they are oriented in the photo.'}, 'i1c2_result': {'score': 1.0, 'description': 'The pet on the left is white and the one on the right is not', 'reasoning': 'In the image, the left pet is a light-colored dog (appears to be white), and the pet on the right is a dark-colored dog (black), which matches the caption accurately.'}, 'i2c1_result': {'score': 1.0, 'description': 'The match between the caption and image', 'reasoning': 'The image shows two pets, with a white dog on the right and a grey cat on the left. The caption accurately describes the color of the pets relative to their position. Therefore, it is very likely that the caption matches the image.'}, 'i2c2_result': {'score': 1.0, 'description': 'The caption accurately describes the image', 'reasoning': "The image shows a white dog on the left and a grey cat on the right, which aligns with the caption's description of the pet on the left being white and the one on the right being not white."}}
{'id': 311, 'scores': array([[0.5, 0. ],
       [0. , 0. ]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/311/0.png', 'img2_path': './winoground/images/311/1.png', 'caption1': 'the green leaves will soon be red as the seasons change', 'caption2': 'the red leaves will soon be green as the seasons change', 'i1c1_result': {'score': 0.5, 'description': 'Neutral', 'reasoning': "While the image shows green leaves which are consistent with the caption 'the green leaves will soon be red as the seasons change', there is not enough contextual information in the image to determine the current season or the likelihood that these particular leaves will turn red. Many types of foliage change color with the seasons, but some do not, and without species identification or additional context it's impossible to assert the likelihood of the change. Therefore, a neutral score is appropriate."}, 'i1c2_result': {'score': 0.0, 'description': 'Mismatch between the caption and the image', 'reasoning': "The image shows green leaves, which contradicts the caption that suggests 'the red leaves will soon be green'. The leaves are already green and do not appear to be changing color in the way the caption suggests."}, 'i2c1_result': {'score': 0.0, 'description': 'The green leaves will soon be red as the seasons change', 'reasoning': 'The image shows leaves that are already in autumnal colors such as orange and brown, and they are covered with frost, indicating that it is likely already late autumn or winter. Therefore, the leaves are past the stage where they would turn red, as that typically happens in early to mid-autumn before they fall off for winter.'}, 'i2c2_result': {'score': 0.0, 'description': 'The red leaves will soon be green as the seasons change.', 'reasoning': 'The image shows leaves with frost on them, which suggests that it is currently autumn or winter. Leaves typically change from green to red or brown in the autumn, not the reverse. Therefore, it is very unlikely that these red leaves will become green soon, as they have likely already gone through the process of changing colors from green to red.'}}
{'id': 313, 'scores': array([[1., 0.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/313/0.png', 'img2_path': './winoground/images/313/1.png', 'caption1': "the moon prevents the sun's rays from falling on the earth", 'caption2': "the earth prevents the sun's rays from falling on the moon", 'i1c1_result': {'score': 1.0, 'description': "The moon prevents the sun's rays from falling on the earth", 'reasoning': 'The image shows a solar eclipse, where the moon is positioned directly between the sun and earth, blocking the sunlight from directly reaching the earth. This aligns with the provided caption.'}, 'i1c2_result': {'score': 0.0, 'description': 'The image shows a solar eclipse.', 'reasoning': "The image depicts a solar eclipse, where the moon moves between the Earth and the Sun, blocking the Sun's rays from reaching the Earth. The caption 'the earth prevents the sun's rays from falling on the moon' suggests a lunar eclipse, which is not what is shown. In a lunar eclipse, the Earth comes between the Sun and the Moon, blocking the Sun's rays from illuminating the Moon. Therefore, the scenario described in the caption does not match the image."}, 'i2c1_result': {'score': 1.0, 'description': "The moon prevents the sun's rays from falling on the earth", 'reasoning': "The image appears to show a lunar eclipse, a phenomenon during which the moon moves into the Earth's shadow, temporarily blocking the sunlight from reaching the moon's surface and, to an extent, the Earth. The bright edge on the moon is consistent with the sun's rays being obstructed by the Earth during a partial phase of the eclipse."}, 'i2c2_result': {'score': 1.0, 'description': 'The image seems to depict a lunar eclipse.', 'reasoning': "The image shows a phenomenon where the Earth comes between the sun and the moon, blocking sunlight from directly reaching the moon. This aligns with the description of a lunar eclipse, where the Earth's shadow falls upon the moon, which is consistent with the caption 'the earth prevents the sun's rays from falling on the moon'. The reddish coloration of the moon is indicative of the light refracting through the Earth's atmosphere and illuminating the moon despite the blockage, a common characteristic of a total lunar eclipse."}}
{'id': 339, 'scores': array([[0., 0.],
       [0., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/339/0.png', 'img2_path': './winoground/images/339/1.png', 'caption1': 'a bird cooking a person', 'caption2': 'a person cooking a bird', 'i1c1_result': {'score': 0.0, 'description': 'A bird cooking a person', 'reasoning': "The image shows an animated depiction of a turkey wearing a chef's hat and apron, wielding a spoon, while two smaller, blue cartoon characters are shown jumping away from a frying pan in distress. The blue characters are abstract and cartoonish, and do not resemble real people. The scenario is clearly intended to be humorous and whimsical, not literal. Birds lack the capability to cook, and the subjects do not resemble the physical reality of birds cooking a person."}, 'i1c2_result': {'score': 0.0, 'description': 'The image depicts an anthropomorphic bird character holding a cooking spoon and wearing a chef hat, not a person cooking a bird.', 'reasoning': "The image does not show a person nor the act of cooking a bird in any literal sense, rather it portrays a stylized, whimsical representation of a bird as a chef. Therefore, it is 'Very Unlikely' that this image matches the caption 'a person cooking a bird'."}, 'i2c1_result': {'score': 0.0, 'description': 'The image depicts a person, presumably a chef, holding a dish with food, which appears to be a traditionally roasted chicken or turkey surrounded by vegetables.', 'reasoning': "The caption 'a bird cooking a person' suggests that a bird would be performing the cooking action on a human, which is not depicted in the image. Instead, the image appears to show a human cooking, which is the opposite scenario of the caption."}, 'i2c2_result': {'score': 1.0, 'description': 'The image depicts a person in chef attire holding a cooked bird, which appears to be a turkey or a similar large bird, typically associated with cooking.', 'reasoning': "The individual is dressed as a chef, complete with a chef's hat, and is holding a platter with a large roasted bird, indicative of cooking. The setting's context with the individual's attire and the appearance of the cooked bird strongly supports the caption 'a person cooking a bird'."}}
{'id': 351, 'scores': array([[1.  , 0.75],
       [1.  , 1.  ]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/351/0.png', 'img2_path': './winoground/images/351/1.png', 'caption1': 'walking someone cut lines into green plants', 'caption2': 'someone walking lines cut into green plants', 'i1c1_result': {'score': 1.0, 'description': 'A person mowing a lawn', 'reasoning': "The image shows a person pushing a lawn mower across a grassy area, which is consistent with the activity of cutting lines into green plants, as lawn mowers are used to cut grass. Since the person is walking and using a device designed for this purpose, the caption 'walking someone cut lines into green plants' matches the activity depicted in the image."}, 'i1c2_result': {'score': 0.75, 'description': 'someone walking lines cut into green plants', 'reasoning': 'The image shows a person using a push reel lawn mower to cut grass in a garden. This suggests that they are in the process of or have been walking in lines to cut into the green plants (grass) as typical mower patterns indicate. However, no distinct lines are yet visible in the grass that indicate a clear pattern or finished result, making the match somewhat likely rather than very likely.'}, 'i2c1_result': {'score': 1.0, 'description': 'The image shows a person walking through a green area with distinctly cut lines.', 'reasoning': 'The person in the image is seen walking through what appears to be a field of green plants with neatly cut lines, which closely matches the caption in question.'}, 'i2c2_result': {'score': 1.0, 'description': 'someone walking lines cut into green plants', 'reasoning': "The image shows a person walking through what appears to be a green plantation with clearly defined pathways or lines cut into it. The plants are green and lush, and the person is actively walking on one of the paths, making the caption 'someone walking lines cut into green plants' a very accurate description of the image."}}
{'id': 361, 'scores': array([[1., 0.],
       [1., 0.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/361/0.png', 'img2_path': './winoground/images/361/1.png', 'caption1': 'on halloween, a child dressed as an insect is to the right of a child dressed as a mammal', 'caption2': 'on halloween, a child dressed as a mammal is to the right of a child dressed as an insect', 'i1c1_result': {'score': 1.0, 'description': 'On Halloween, a child dressed as an insect is to the right of a child dressed as a mammal', 'reasoning': 'In the image, there is a child dressed in a costume with antennae, wings, and what appears to be an abdomen segment, which are characteristics of an insect. To the immediate left of this child (which is right from the perspective of the children) is another child dressed in a costume that resembles a mammal, with a tail, ears, and paws. Given that this is a typical scene on Halloween where children dress up in costumes, the description provided matches the image very well.'}, 'i1c2_result': {'score': 0.0, 'description': 'There is no child dressed as a mammal to the right of a child dressed as an insect.', 'reasoning': 'In the image provided, there are several children dressed in various costumes for Halloween. From left to right, we see a child dressed as a rabbit, a cowboy, a magician, a bee, a skeleton, a fairy, and a child in a nature-inspired costume. There are no mammal costumes to the immediate right of the bee costume, as a skeleton costume and fairy costume are respectively to the immediate and further right of the bee costume. Therefore, the image does not match the caption provided.'}, 'i2c1_result': {'score': 1.0, 'description': 'On Halloween, a child dressed as an insect is to the right of a child dressed as a mammal', 'reasoning': 'In the provided image, a group of children are dressed in various costumes. To the right of the image, a child is dressed in a costume with furry brown spots, resembling a mammal (likely a leopard based on the pattern), and to the immediate right of this child, another child is dressed in an all-black costume with attached wings and antennae, suggestive of an insect costume.'}, 'i2c2_result': {'score': 0.0, 'description': 'In the provided image, there does not appear to be a child dressed as a mammal to the immediate right of a child dressed as an insect on Halloween.', 'reasoning': 'The children’s costumes in the image comprise of various characters and none to the right of an insect costume. While there are costumes that could loosely be interpreted as mammals (like the child dressed in a brown outfit that could suggest an animal theme), there is no clear representation of an insect immediately to the right of such a costume, therefore making the caption a very unlikely match.'}}
{'id': 375, 'scores': array([[1., 0.],
       [1., 0.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/375/0.png', 'img2_path': './winoground/images/375/1.png', 'caption1': 'living things drinking', 'caption2': 'drinking living things', 'i1c1_result': {'score': 1.0, 'description': 'The image shows multiple cows with their heads down at a water trough, which visually indicates that they are drinking from it. Cows are living things, and the action they are engaged in is consistent with drinking.', 'reasoning': "The image directly depicts a group of living creatures (cows) engaging in the act of drinking water, therefore it very closely matches the caption 'living things drinking'. There are no significant elements in the image to suggest otherwise."}, 'i1c2_result': {'score': 0.0, 'description': 'drinking living things', 'reasoning': "The image shows a group of cattle drinking water from what appears to be a trough or water body. The caption 'drinking living things' is not accurate as the cattle are drinking water, which is not a 'living thing.' The correct description would involve the cattle drinking water or hydrating."}, 'i2c1_result': {'score': 1.0, 'description': "The caption 'living things drinking' accurately describes the content of the image", 'reasoning': 'The image shows a person drinking from a cup, and a person is a living thing. The action depicted is clearly that of drinking, which matches the given caption.'}, 'i2c2_result': {'score': 0.0, 'description': 'The image shows a person drinking from a small container, likely a yogurt or similar food product.', 'reasoning': "The container does not suggest that it contains living things, and the act of drinking typically does not involve live organisms. The caption 'drinking living things' is not a common or likely description for this image."}}
{'id': 379, 'scores': array([[1., 0.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/379/0.png', 'img2_path': './winoground/images/379/1.png', 'caption1': 'a person carrying more than one flotation device', 'caption2': 'more than one flotation device carrying a person', 'i1c1_result': {'score': 1.0, 'description': 'a person carrying more than one flotation device', 'reasoning': 'The individual in the image is clearly carrying multiple inflatable flotation devices, including ones designed as unicorns and various food items, indicating that the caption matches the contents of the image very closely.'}, 'i1c2_result': {'score': 0.0, 'description': "The provided image does not match the caption 'more than one flotation device carrying a person'.", 'reasoning': 'The image shows a person carrying multiple uninflated flotation devices. None of the devices are in the water carrying a person, which is what the caption suggests.'}, 'i2c1_result': {'score': 1.0, 'description': 'A person carrying more than one flotation device', 'reasoning': 'The image shows a person with multiple colorful flotation rings stacked up around their torso, clearly carrying more than one flotation device.'}, 'i2c2_result': {'score': 1.0, 'description': 'The image depicts a person seated on top of stacked flotation devices in a body of water.', 'reasoning': "The image clearly shows a person sitting atop multiple flotation devices (specifically, inflated tubes) placed one on top of the other, in what appears to be a pool or similar body of water. This matches the caption's description of 'more than one flotation device carrying a person.'"}}
{'id': 383, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/383/0.png', 'img2_path': './winoground/images/383/1.png', 'caption1': 'a toy herbivore stands on top of at least one toy carnivore', 'caption2': 'at least one toy herbivore stands on top of a toy carnivore', 'i1c1_result': {'score': 1.0, 'description': 'A toy herbivore stands on top of at least one toy carnivore', 'reasoning': "The image displays two toy dinosaurs. The one on top, with the distinctive plates along its back, resembles a Stegosaurus, which was a herbivore. The toy it stands on top of resembles a carnivorous dinosaur, possibly a Spinosaurus, given the sail-like structure on its back. Below the presumed Spinosaurus is another dinosaur, which due to its bipedal posture and sharp teeth, also resembles a carnivorous dinosaur, such as a Tyrannosaurus rex. Hence, there is a toy herbivore standing on top of at least one toy carnivore, which makes the caption 'Very Likely' to be a match."}, 'i1c2_result': {'score': 1.0, 'description': 'There appears to be a toy herbivore (a dinosaur resembling a Stegosaurus) standing on top of a toy carnivore (a dinosaur resembling a Tyrannosaurus rex).', 'reasoning': 'Based on the visible characteristics of the toy dinosaurs, the top one has plates along its back which are commonly associated with herbivorous dinosaurs like Stegosaurus, and the bottom one has physical traits similar to that of a carnivorous dinosaur, possibly a Tyrannosaurus rex. Therefore, the caption accurately describes the situation depicted in the image.'}, 'i2c1_result': {'score': 1.0, 'description': 'A toy herbivore stands on top of at least one toy carnivore', 'reasoning': 'The image shows toy dinosaur figures stacked on top of each other. The topmost figure resembles a herbivorous dinosaur, such as a Stegosaurus, due to the presence of plates on its back which is characteristic of certain herbivorous dinosaurs. Below it, there are figures that resemble carnivorous dinosaurs, identifiable by their sharp teeth and bipedal stance, similar to that of a Tyrannosaurus rex and Velociraptor. Since the herbivorous figure is standing on figures that are characteristic of carnivores, the caption is very likely to be a match.'}, 'i2c2_result': {'score': 1.0, 'description': 'At least one toy herbivore stands on top of a toy carnivore', 'reasoning': 'The image displays toy dinosaur figures stacked on top of each other. The top toy resembles a Stegosaurus, which is a known herbivore, and it stands on top of other dinosaur figures that appear to be theropods, likely representing carnivores. As the caption accurately describes the scenario depicted in the image, the likelihood that the caption matches the image is very high.'}}
{'id': 387, 'scores': array([[0., 1.],
       [0., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/387/0.png', 'img2_path': './winoground/images/387/1.png', 'caption1': 'There are not pink flowers below the bird with yellow head feathers', 'caption2': 'There are pink flowers not below the bird with yellow head feathers', 'i1c1_result': {'score': 0.0, 'description': 'The caption does not match the image', 'reasoning': 'The provided image shows a bird with yellow head feathers, which matches the description in the caption. However, below the bird, there are clearly pink flowers, which directly contradicts the caption stating that there are not pink flowers below the bird.'}, 'i1c2_result': {'score': 1.0, 'description': 'There are pink flowers not below the bird with yellow head feathers', 'reasoning': 'The image shows a bird which appears to have yellow head feathers, hanging from a branch with pink flowers. The pink flowers are positioned around and above the bird, thus no pink flowers are directly below the bird.'}, 'i2c1_result': {'score': 0.0, 'description': 'There are pink flowers below the bird with yellow head feathers', 'reasoning': 'The image clearly shows a bird with yellow head feathers surrounded by pink flowers, which are positioned below it as well. This directly contradicts the statement provided in the caption.'}, 'i2c2_result': {'score': 1.0, 'description': 'There are pink flowers not below the bird with yellow head feathers', 'reasoning': 'The image displays a bird with yellow head feathers, positioned among pink flowers. The flowers are indeed not below the bird, but instead, they are around and above the bird, making the caption a very likely match to the image.'}}
{'id': 389, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/389/0.png', 'img2_path': './winoground/images/389/1.png', 'caption1': 'water is on and under a vessel', 'caption2': 'a vessel is on and under water', 'i1c1_result': {'score': 1.0, 'description': 'The image shows a vessel, likely a cruise ship, with visible water on the deck and the ocean surrounding it.', 'reasoning': 'There is clear evidence of a vessel, with water on the deck in the form of a pool, and the surrounding ocean underlines the fact that there is water under the vessel as well. Therefore, the caption matches the content of the image accurately.'}, 'i1c2_result': {'score': 1.0, 'description': 'A vessel is on and under water', 'reasoning': "The provided image shows a ship's deck with multiple amenities, and it is evident that the vessel is afloat as we can see the water surrounding it and in motion. By virtue of being a ship, a portion of it is submerged under the waterline, making the caption 'a vessel is on and under water' very likely to be accurate."}, 'i2c1_result': {'score': 1.0, 'description': 'Water is on and under a vessel', 'reasoning': "The image shows a submersible vessel underwater, indicating that water is indeed both surrounding it (on) and beneath it (under). This matches the given caption very accurately, thus justifying a 'Very Likely' score."}, 'i2c2_result': {'score': 1.0, 'description': 'The image shows a submarine-like vehicle submerged underwater, indicating that it is a vessel designed to operate below the water surface.', 'reasoning': "The vessel in the image appears to be fully submerged and designed for underwater travel, consistent with the caption indicating that it is both 'on and under water.' The terminology 'on water' would typically suggest that the vessel is floating at the surface, but since the vehicle shown is capable of moving under water, the caption is still considered very likely accurate."}}
{'id': 393, 'scores': array([[1., 1.],
       [1., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/393/0.png', 'img2_path': './winoground/images/393/1.png', 'caption1': 'head in the clouds', 'caption2': 'clouds in the head', 'i1c1_result': {'score': 1.0, 'description': "The provided image matches the caption 'head in the clouds'.", 'reasoning': "In the image, a person is sitting with their head obscured by a cloud, creating the literal impression that their head is in a cloud. This matches the idiomatic expression 'head in the clouds', which is often used to describe a person who is lost in thought or daydreaming."}, 'i1c2_result': {'score': 1.0, 'description': "The provided image shows a person sitting with their head obscured by a cloud, which creates the illusion that the cloud is in place of their head. This visual metaphor is a direct representation of the caption 'clouds in the head'.", 'reasoning': "The image literalizes the concept by replacing the person's head with a cloud; hence, there is a very strong visual correspondence between the caption and the image."}, 'i2c1_result': {'score': 1.0, 'description': "The image visually represents a silhouette of a person's head, within which is depicted a cloud raining down, effectively creating a strong metaphorical association with the phrase 'head in the clouds'.", 'reasoning': "The image clearly shows a cloud inside the outline of a human head, which directly correlates to the figurative meaning of the phrase 'head in the clouds', often used to describe someone who is not paying attention to what is happening around them because they are so lost in their own thoughts or dreams. The graphical representation in the image closely matches the caption provided."}, 'i2c2_result': {'score': 1.0, 'description': 'The silhouette of a head filled with a cloud', 'reasoning': "The image features a silhouette of a human head with an illustrated cloud inside it. The expression 'clouds in the head' is often used metaphorically to describe a state of confusion or daydreaming, and the imagery strongly supports this idea. The literal cloud within the head silhouette visually communicates this concept, making a 'Very Likely' match to the caption."}}
{'id': 153, 'scores': array([[0., 0.],
       [0., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/153/0.png', 'img2_path': './winoground/images/153/1.png', 'caption1': 'books holding up a person', 'caption2': 'a person holding up books', 'i1c1_result': {'score': 0.0, 'description': "The image shows a person inserted between bookshelves in a way that creates an optical illusion, making it seem as if they are suspended or supported horizontally by books. The books are vertically stacked on the floor, and they are not physically supporting the person in a literal sense, as suggested by the caption 'books holding up a person'. Instead, the person appears to be supporting themselves against the bookshelves.", 'reasoning': "Upon close inspection, it is clear that the books are not structurally supporting the person's weight in any capacity. The person is not positioned above the books in a manner that would imply the books are holding them up. The arrangement of the scene is a playful trick of perspective, not a physical reality, therefore the caption does not accurately describe what is depicted."}, 'i1c2_result': {'score': 0.0, 'description': 'A person climbing a bookshelf', 'reasoning': 'The person in the image is actually climbing a bookshelf and is not holding up any books. There is a stack of books on the ground, but they are not being held by the person.'}, 'i2c1_result': {'score': 0.0, 'description': 'Books holding up a person', 'reasoning': 'The image shows a person holding a stack of books above their head, not books holding up a person. Therefore, the caption does not accurately describe what is depicted in the image.'}, 'i2c2_result': {'score': 1.0, 'description': 'A person holding up books', 'reasoning': 'The image shows a person with a stack of books on their head. Although the books are not being held up with their hands, the person is still physically supporting the books in an elevated position. The environment appears to be a library, which is a common place for books, further supporting the caption.'}}
{'id': 157, 'scores': array([[1., 1.],
       [0., 1.]]), 'text_score': 0, 'image_score': 0, 'group_score': 0, 'img1_path': './winoground/images/157/0.png', 'img2_path': './winoground/images/157/1.png', 'caption1': 'the flowers are taller than the people', 'caption2': 'the people are taller than the flowers', 'i1c1_result': {'score': 1.0, 'description': 'The flowers are taller than the people', 'reasoning': 'In the image provided, there are two children standing in front of a wooden fence on which sunflowers are growing taller than the fence. Since the sunflowers are taller than the fence and the children are shorter than the fence, it is very likely that the flowers are taller than the people.'}, 'i1c2_result': {'score': 1.0, 'description': 'The people are taller than the flowers', 'reasoning': 'The two individuals in the image are visibly taller than the flowers in the background. Their heads are above the top of the fence, while the sunflowers, though tall, do not surpass the fence by a large margin, indicating the individuals are taller than the flowers.'}, 'i2c1_result': {'score': 0.0, 'description': 'The flowers are not taller than the people', 'reasoning': "The image shows a couple standing in a field of sunflowers. The sunflowers, while relatively large, do not appear to be taller than the people. In fact, the tops of the sunflower heads are visibly below the height of the people's heads."}, 'i2c2_result': {'score': 1.0, 'description': 'The people are taller than the flowers', 'reasoning': 'In the image, we can observe two people standing in a field of sunflowers. The people are visibly taller than the surrounding sunflowers, with their heads and upper bodies extending above the tops of the flowers.'}}
{'id': 245, 'scores': array([[1., 0.],
       [0., 1.]]), 'text_score': 1, 'image_score': 1, 'group_score': 1, 'img1_path': './winoground/images/245/0.png', 'img2_path': './winoground/images/245/1.png', 'caption1': 'food on their eyes', 'caption2': 'eyes on their food', 'i1c1_result': {'score': 1.0, 'description': 'The image shows a person with slices of cucumber over their eyes.', 'reasoning': "The phrase 'food on their eyes' quite literally describes the scene, where the person has placed slices of food (cucumber) over their eyes."}, 'i1c2_result': {'score': 0.0, 'description': 'The image depicts a person holding slices of cucumber over their eyes, not focused on food as something to eat.', 'reasoning': "The caption 'eyes on their food' suggests someone looking at food with the interest of eating it. In the image provided, the person appears to be using cucumber slices as part of a beauty regimen rather than focusing on the cucumber as food to be eaten. Therefore, the concept of having an intent to consume the food is not represented in the image."}, 'i2c1_result': {'score': 0.0, 'description': "The caption 'food on their eyes' does not match the image", 'reasoning': "The image shows a plate with food arranged to look like a face with eyes, but the food is not placed on anyone's eyes. The caption suggestively describes a scenario where food is placed on a person's eyes, which is not depicted in the image."}, 'i2c2_result': {'score': 1.0, 'description': 'The image visually portrays food items arranged in such a way that they resemble faces with eyes.', 'reasoning': "The food on the plate has been decorated to look like faces, complete with 'eyes' made from food items such as olives and cucumber slices, hence literally having 'eyes on the food'. The caption accurately describes the visual pun or creative presentation style depicted in the image."}}
