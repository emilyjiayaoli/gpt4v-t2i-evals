{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from path... TIFA160_DSG Access denied with the following error:\n",
      "Done!\n",
      "Spearman's Correlation (ours):  61.167074489741616\n",
      "Kendall Tau Score (ours):  SignificanceResult(statistic=0.4737075366229423, pvalue=4.544395849224196e-75)\n",
      "Kendall Tau-C Score (ours):  47.00540625000001\n",
      "Accuracy of selecting best human score image (ours): 0.69375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1hHVMeVDZlnJz1FFhy_BxiZGIz1tEMm0s \n",
      "\n",
      "unzip:  cannot find or open tifa160.zip, tifa160.zip.zip or tifa160.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "from evaluation import GPT4Vision_Evals as evals\n",
    "\n",
    "# 1) Define prompt or import existing prompts from prompt.py\n",
    "def VIEScore_baseline_prompt():\n",
    "    system_msg = '''You are a professional digital artist. You will have to evaluate the effectiveness of the AI-generated image(s) based on the given rules. You will have to give your output in this way (Keep your reasoning concise and short.): \\\n",
    "                        {\n",
    "                            \\\"score\\\" : [...],\n",
    "                            \\\"reasoning\\\" : \\\"...\\\"\n",
    "                        }'''\n",
    "    user_msg = \"RULES: The image is an AI-generated image according to the text prompt. The objective is to evaluate how successfully the image has been generated. On a scale 0 to 10: A score from 0 to 10 will be given based on the success in following the prompt. (0 indicates that the AI-generated image does not follow the prompt at all. 10 indicates the AI-generated image follows the prompt perfectly.) Put the score in a list such that output score = [score]. Text Prompt: {img_caption}\"    \n",
    "    # user_msg += \"Provide your evaluation in JSON format, including keys for 'score' and 'reasoning'.\"\n",
    "    return system_msg, user_msg\n",
    "\n",
    "# 2) Define other args\n",
    "system_msg, user_msg = VIEScore_baseline_prompt()               # Defines prompt (change me)\n",
    "dataset_name = \"TIFA160_DSG\"                                    # Dataset name (change me) - see dataset.py for all provided datasets\n",
    "eval_method_name = \"VIEScore\"                                   # Method name (change me)\n",
    "save_folder_name = f\"logs/{dataset_name}/{eval_method_name}/\"   # Log folder path (change me)\n",
    "openai_api_key = 'YOUR API KEY'\n",
    "\n",
    "# 3) Define evaluator & Run evaluation\n",
    "evaluator = evals(save_folder_name, openai_api_key, dataset_name=dataset_name,\n",
    "                  post_processing_fn=None, # Post processing function to apply to the generated text. Default: None\n",
    "                  system_prompt=system_msg, user_prompt=user_msg, # Prompt to use for evaluation\n",
    "                  api_max_retries=2, # Number of times to retry API call before giving up\n",
    "                  )\n",
    "\n",
    "# 4) Reset API key (optional)\n",
    "evaluator.reset_api_key(openai_api_key) # Ensure that the correct API key is used\n",
    "\n",
    "# 5) Run evaluation  \n",
    "# evaluator.evaluate_gpt4v(list(range(0,20)))    # Option 1: Evaluate by list of ids\n",
    "# evaluator.evaluate_gpt4v()                     # Option 2: Evaluate all ids in dataset\n",
    "\n",
    "# 6) Get results: Results are automatically saved every 10 samples or when error occurs, and will be loaded automatically when evaluator is re-initialized\n",
    "results = evaluator.get_results()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wg-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
